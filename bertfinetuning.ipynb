{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7860112,"sourceType":"datasetVersion","datasetId":4610716},{"sourceId":7884400,"sourceType":"datasetVersion","datasetId":4628067}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sivamanivallabhani/bertfinetuning?scriptVersionId=175467008\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Regular imports\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn\nimport numpy as np \ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Import torch.nn.functional as F\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2024-05-03T14:19:45.279309Z","iopub.execute_input":"2024-05-03T14:19:45.279687Z","iopub.status.idle":"2024-05-03T14:19:46.932894Z","shell.execute_reply.started":"2024-05-03T14:19:45.279654Z","shell.execute_reply":"2024-05-03T14:19:46.932027Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Define data path\ndata_path = \"/kaggle/input/davidson1/labeled_data.csv\"\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T14:19:47.482783Z","iopub.execute_input":"2024-05-03T14:19:47.484007Z","iopub.status.idle":"2024-05-03T14:19:47.489287Z","shell.execute_reply.started":"2024-05-03T14:19:47.483939Z","shell.execute_reply":"2024-05-03T14:19:47.488435Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load data\nimport pandas as pd\ndata = pd.read_csv(data_path)\ndf = pd.DataFrame(data)\ndf.columns = ['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither',\n              'classk', 'tweet']\ndf[\"classk\"] = df[\"classk\"].map({2:1, 1:0, 0:0})  # Convert labels to binary (hate vs not hate)\ntweets = df.tweet\nres = []\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T14:19:49.237875Z","iopub.execute_input":"2024-05-03T14:19:49.238261Z","iopub.status.idle":"2024-05-03T14:19:49.7887Z","shell.execute_reply.started":"2024-05-03T14:19:49.23823Z","shell.execute_reply":"2024-05-03T14:19:49.787383Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Process tweets\nfor i in range(len(tweets)):\n    splitt = tweets[i].split(\":\")\n    if len(splitt) == 1:\n        res.append(splitt[0])\n    else:\n        res.append(splitt[-1])\n\ntweets = res","metadata":{"execution":{"iopub.status.busy":"2024-05-03T14:19:51.118429Z","iopub.execute_input":"2024-05-03T14:19:51.119085Z","iopub.status.idle":"2024-05-03T14:19:51.218565Z","shell.execute_reply.started":"2024-05-03T14:19:51.119044Z","shell.execute_reply":"2024-05-03T14:19:51.217772Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\n# Import tokenizer and BERT model\nfrom transformers import AutoTokenizer, BertModel\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\nmodel = BertModel.from_pretrained(\"bert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-05-03T14:19:52.938171Z","iopub.execute_input":"2024-05-03T14:19:52.938798Z","iopub.status.idle":"2024-05-03T14:20:00.379205Z","shell.execute_reply.started":"2024-05-03T14:19:52.938751Z","shell.execute_reply":"2024-05-03T14:20:00.378313Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be1acfac179248a2a123bff5b17054a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e939197be90c4fc8baed9ebed0c1c350"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12ae063d366541e9af4131f3a90dc3f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86840a081b604fbcac483648cc554b02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"762cdbd63ea145b58bc29e27a72dfa47"}},"metadata":{}}]},{"cell_type":"code","source":"# Define custom dataset class\nclass Custom_Dataset(torch.utils.data.Dataset):\n    def __init__(self, data, labels):\n        self.data = data\n        self.labels = labels\n        \n    def __getitem__(self, index: int) -> (torch.Tensor, int):\n        X = self.data[index]\n        y = self.labels[index]\n        return (X, y)\n    \n    def __len__(self) -> int:\n        return len(self.data)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T14:20:01.665948Z","iopub.execute_input":"2024-05-03T14:20:01.666659Z","iopub.status.idle":"2024-05-03T14:20:01.672514Z","shell.execute_reply.started":"2024-05-03T14:20:01.666616Z","shell.execute_reply":"2024-05-03T14:20:01.671567Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Split data into train and test sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(tweets, list(df.classk), test_size=0.2, shuffle=True)\n\n# Define train and test datasets and dataloaders\ntrain_data = Custom_Dataset(data=X_train, labels=y_train)\ntest_data = Custom_Dataset(data=X_test, labels=y_test)\ntrain_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=3, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=1, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T14:20:03.26804Z","iopub.execute_input":"2024-05-03T14:20:03.268771Z","iopub.status.idle":"2024-05-03T14:20:03.822101Z","shell.execute_reply.started":"2024-05-03T14:20:03.268738Z","shell.execute_reply":"2024-05-03T14:20:03.821273Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Model0(nn.Module):\n    def __init__(self, model, tokenizer):\n        super().__init__()\n        self.tokenizer = tokenizer\n        self.model = model\n        self.fc1 = nn.Linear(768, 256)  # Additional layer for fine-tuning\n        self.fc2 = nn.Linear(256, 2)     # Output layer\n\n    def forward(self, X):\n        inputs = self.tokenizer(X, return_tensors=\"pt\").to(device)\n        outputs = self.model(**inputs)\n        outputs = outputs.last_hidden_state[0][0].unsqueeze(1)\n\n        \n        # Additional layers for fine-tuning\n        outputs = torch.relu(self.fc1(outputs.squeeze()))  # Remove extra dimension\n        outputs = self.fc2(outputs)\n\n        return outputs\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T14:20:05.252615Z","iopub.execute_input":"2024-05-03T14:20:05.253314Z","iopub.status.idle":"2024-05-03T14:20:05.259764Z","shell.execute_reply.started":"2024-05-03T14:20:05.253275Z","shell.execute_reply":"2024-05-03T14:20:05.258696Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Instantiate the model\nmodel0 = Model0(model, tokenizer)\nmodel0.to(device)\n\n# Define the optimizer\noptimizer = torch.optim.Adam(params=model0.parameters(), lr=0.00002)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T14:02:42.875782Z","iopub.execute_input":"2024-05-03T14:02:42.876618Z","iopub.status.idle":"2024-05-03T14:02:43.14327Z","shell.execute_reply.started":"2024-05-03T14:02:42.87659Z","shell.execute_reply":"2024-05-03T14:02:43.142222Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Define the inter and intra space loss functions\ndef L_inter(spaces):\n    means = [torch.mean(spaces[i]) for i in range(spaces.shape[0])]\n    loss = torch.tensor(0.0, requires_grad=True)\n    for k in range(len(means)):\n        cur = torch.tensor(0.0, requires_grad=True)\n        for l in range(len(means)):\n            if l == k:\n                continue\n            cur = cur + (1 / (1 - ((means[k] * means[l]))))\n        loss = loss + cur\n    return loss\n\ndef L_intra(spaces):\n    loss = torch.tensor(0.0, requires_grad=True)\n    for k in range(len(spaces)):\n        loss = loss + 1 / torch.var(spaces[k], dim=0)\n    return torch.sum(loss) / loss.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-03T14:02:43.148372Z","iopub.execute_input":"2024-05-03T14:02:43.148731Z","iopub.status.idle":"2024-05-03T14:02:43.158316Z","shell.execute_reply.started":"2024-05-03T14:02:43.148704Z","shell.execute_reply":"2024-05-03T14:02:43.15722Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\ncorrect = 0\ntotal = len(y_test)\n\ntrue = []\npreds = []\n\nwith torch.no_grad():\n    for i, batch in enumerate(test_loader):\n#         if i == 100 :\n#             break\n        X, y = batch\n        y_preds = model0(X)\n\n        # Move y tensor to the same device as y_preds\n        y = y.to(y_preds.device)\n\n        y_predict = torch.argmax(y_preds)\n\n        true.extend(y.cpu())  # Move true labels back to CPU\n        preds.append(y_predict.cpu())  # Move predictions back to CPU\n\n        cur = torch.eq(y_predict, y)\n\n        correct += torch.sum(cur)\n\nprint(f\"Test Accuracy: {correct/total}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T14:02:43.159968Z","iopub.execute_input":"2024-05-03T14:02:43.160273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nmodel0.train()\ntry:\n    for _ in range(5):\n        for i, batch in enumerate(train_loader):\n#             if i==100:\n#                 break\n            if i % 2000 == 0:\n                print(i)\n\n            X, Y = batch\n            loss = 0\n\n            for X, y in zip(X, Y):\n                y_preds = model0(X)\n                loss += F.cross_entropy(y_preds.view(1, -1).to(device), torch.tensor([y]).to(device))\n\n            loss /= len(Y)\n#             loss += 0.7 * L_inter(torch.cat((hate_space, not_hate_space))) + 0.5 * L_intra(torch.stack([hate_space, not_hate_space]))\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        \n\nexcept KeyboardInterrupt:\n    print(\"Training interrupted by the user.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\ncorrect = 0\ntotal = len(y_test)\n\ntrue = []\npreds = []\n\nwith torch.no_grad():\n    for i, batch in enumerate(test_loader):\n#         if i == 100 :\n#             break\n        X, y = batch\n        y_preds = model0(X)\n\n        # Move y tensor to the same device as y_preds\n        y = y.to(y_preds.device)\n\n        y_predict = torch.argmax(y_preds)\n\n        true.extend(y.cpu())  # Move true labels back to CPU\n        preds.append(y_predict.cpu())  # Move predictions back to CPU\n\n        cur = torch.eq(y_predict, y)\n\n        correct += torch.sum(cur)\n\nprint(f\"Test Accuracy: {correct/total}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define hate and not_hate words\nhate_words = ['Moist', 'Cunt', 'Panties', 'Fuck', 'Hate', 'Nigger', 'Pussy', 'Ass', \n              'Motherfucker', 'Bitch', 'Damn']\nnot_hate_words = ['Love', 'Peace', 'Kindness', 'Happiness', 'Respect', 'Friendship',\n                  'Appreciation', 'Hope', 'Encouragement', 'Support', 'Caring']","metadata":{"execution":{"iopub.status.busy":"2024-05-03T14:20:20.903191Z","iopub.execute_input":"2024-05-03T14:20:20.903549Z","iopub.status.idle":"2024-05-03T14:20:20.908611Z","shell.execute_reply.started":"2024-05-03T14:20:20.903521Z","shell.execute_reply":"2024-05-03T14:20:20.907548Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#contrastive loss fucntion \ndef kl_divergence(p, q):\n    return (p * (p / q).log()).sum()\ndef ContrastiveLoss():\n    sum=0\n    for i in hate_words:\n        for j in not_hate_space: \n            sum+=kl_divergence(i,j)\n            ","metadata":{"execution":{"iopub.status.busy":"2024-05-03T14:28:14.118381Z","iopub.execute_input":"2024-05-03T14:28:14.118759Z","iopub.status.idle":"2024-05-03T14:28:14.125423Z","shell.execute_reply.started":"2024-05-03T14:28:14.118732Z","shell.execute_reply":"2024-05-03T14:28:14.123759Z"},"trusted":true},"execution_count":17,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[17], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def ContrastiveLoss():\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"],"ename":"SyntaxError","evalue":"incomplete input (1525118760.py, line 2)","output_type":"error"}]},{"cell_type":"code","source":"import torch.nn.functional as F\n\n# Example usage:\npredicted_probs = torch.tensor([[0.9, 0.1], [0.3, 0.7], [0.8, 0.2]])\ntarget_labels = torch.tensor([0, 1, 0])  # Assuming binary classification\nce_loss = F.cross_entropy(predicted_probs, target_labels)\nce_loss","metadata":{"execution":{"iopub.status.busy":"2024-05-03T14:31:12.965288Z","iopub.execute_input":"2024-05-03T14:31:12.965699Z","iopub.status.idle":"2024-05-03T14:31:12.975244Z","shell.execute_reply.started":"2024-05-03T14:31:12.965667Z","shell.execute_reply":"2024-05-03T14:31:12.973902Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"temp = []\nfor word in hate_words:\n    inputs = tokenizer(word, return_tensors=\"pt\").to(device)\n    outputs = model(**inputs)\n    outputs = torch.mean(outputs.last_hidden_state[0][1:], dim=0)\n    temp.append(outputs.tolist())\n\nhate_space = torch.tensor(temp).to(device).requires_grad_()\n\n# Process not_hate words\ntemp = []\nfor word in not_hate_words:\n    inputs = tokenizer(word, return_tensors=\"pt\").to(device)\n    outputs = model(**inputs)\n    outputs = torch.mean(outputs.last_hidden_state[0][1:], dim=0)\n    temp.append(outputs.tolist())\n\nnot_hate_space = torch.tensor(temp).to(device).requires_grad_()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T14:20:22.453592Z","iopub.execute_input":"2024-05-03T14:20:22.453973Z","iopub.status.idle":"2024-05-03T14:20:23.449567Z","shell.execute_reply.started":"2024-05-03T14:20:22.453943Z","shell.execute_reply":"2024-05-03T14:20:23.448754Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import random\nl=[[random.uniform(0,1)] for i in range(11)]\nl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hate_space.max(1)[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-03T14:21:46.774919Z","iopub.execute_input":"2024-05-03T14:21:46.775296Z","iopub.status.idle":"2024-05-03T14:21:46.782207Z","shell.execute_reply.started":"2024-05-03T14:21:46.775267Z","shell.execute_reply":"2024-05-03T14:21:46.78118Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor([1.1603, 0.8926, 1.1271, 1.6617, 1.2231, 1.5119, 0.9701, 0.9552, 1.3656,\n        1.2014, 1.5585], grad_fn=<MaxBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"# next(iter(test_loader)) \ntensor_shape = (11,1)\nhate_space_weights = torch.tensor(l).to(device).requires_grad_()\nnot_hate_space_weights = torch.tensor(l).to(device).requires_grad_()\n\nprint(hate_space_weights.device,not_hate_space_weights.is_leaf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hate_space_weights.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hate_space_weights.is_leaf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass Model1(nn.Module):\n\n    def __init__(self, model, tokenizer):\n        super().__init__()\n        self.tokenizer = tokenizer\n        self.model = model\n\n    def forward(self, X):\n        inputs = self.tokenizer(X, return_tensors=\"pt\").to(device)\n        outputs = self.model(**inputs)\n        outputs = outputs.last_hidden_state[0][1:len(outputs.last_hidden_state[0])].transpose(0, 1)#shape=>(768,no of tokens)\n        col_norms = torch.norm(outputs, p=2, dim=0, keepdim=True)\n        outputs = outputs / col_norms#  makes every word resp unit vector \n        hate_att_scores=torch.matmul(hate_space/torch.norm(hate_space,p=2, dim=0, keepdim=True),outputs)#shape=>(11,v)\n        not_hate_att_scores=torch.matmul(not_hate_space/torch.norm(not_hate_space,p=2, dim=0, keepdim=True),outputs)#shape=>(11,v)\n        Psk_hate = torch.matmul(hate_att_scores.max(1)[0], hate_space_weights)#shape=>(1)\n        Psk_not_hate = torch.matmul(not_hate_att_scores.max(1)[0], not_hate_space_weights)#shape=>(1)\n        output_tensor = torch.cat((Psk_hate, Psk_not_hate), dim=0).requires_grad_()#\n        return output_tensor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = Model1(model, tokenizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def L_inter(spaces):\n    \"\"\"this function calculates inter space losses between spaces \n    forces the class spaces of different class to move apart\n    \"\"\"\n    means = [torch.mean(spaces[i]) for i in range(spaces.shape[0])]\n    \n    loss = torch.tensor(0.0, requires_grad=True)\n    \n    for k in range(len(means)):\n        cur = torch.tensor(0.0, requires_grad=True)\n        for l in range(len(means)):\n            if l == k:\n                continue\n            cur = cur + (1 / (1 - ((means[k] * means[l]))))\n        \n        loss = loss + cur\n    \n    return loss\n            \n            \n\ndef L_intra(spaces):\n    \"\"\"\"this function calculates intra space loss \nforces the vector representations inside a class space to have high variability(varience)\n\"\"\"\n    loss=torch.tensor(0.0, requires_grad=True)\n    for k in range(len(spaces)):\n        loss=loss+1/torch.var(spaces[k], dim=0)\n    \n    return torch.sum(loss)/loss.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(hate_space,not_hate_space)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(hate_space_weights,not_hate_space_weights)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score,accuracy_score\n\n\nmodel1.to(device)\n\nprint(hate_space.is_leaf)\noptimizer = torch.optim.Adam(params=[hate_space, not_hate_space, hate_space_weights, not_hate_space_weights], lr=0.0002)\nmodel1.train()\n\n\ncurr=0.1\nprev=0\npprev=0\nfor _ in range(5):\n    for i, batch in enumerate(train_loader):\n#         if i == 100:\n#             break\n        if i % 2000 == 0:\n            print(i)\n\n        x, Y = batch\n        loss = 0\n\n        for X, y in zip(x, Y):\n            probs = model1(X)\n#             print(y_preds)\n            #print(f\"printing y_preds={y_preds} shape={y_preds.shape}\")\n\n            loss+=F.cross_entropy(probs.view(1, -1).to(device), torch.tensor([y]).to(device))\n            \"\"\"explisit soft max is not used to convert to probs is cross \n            entrophy loss has inbuilt softmax  function adding softmax explisity\n            will effect adversly by smoothing again on smoothed values will decrese \n            the weightage for class with high prob \"\"\"\n#             break\n        loss /= len(x)\n        loss += 1*L_inter(torch.cat((hate_space, not_hate_space))) + 1*L_intra(torch.stack([hate_space, not_hate_space]))\n            \n        optimizer.zero_grad()\n        \n        loss.backward()\n        optimizer.step()\n#         print(hate_space.grad,hate_space_weights.grad)\n    correct = 0\n    total = len(y_test)\n\n    true = []\n    preds = []\n\n    with torch.inference_mode():\n        for i, batch in enumerate(test_loader):\n#             if i==100:\n#                 break\n\n            X, y = batch\n            Psk_hate, Psk_not_hate = model1(X)\n\n            y_predict = torch.argmax(torch.tensor([Psk_hate.mean().item(), Psk_not_hate.mean().item()]))\n\n            true.extend(y)\n            preds.append(y_predict)\n\n            cur = torch.eq(y_predict, y)\n\n            correct += torch.sum(cur)\n    pprev=prev\n    prev=curr\n    print(f\"Test Accuracy: {correct/total}\")\n    curr=correct/total\n    print(f\"Accuracy - {accuracy_score(y_test, preds)}\")\n    print(f\"precison score -{precision_score(y_test, preds, average='macro')}\")\n    print(f\"recall score  -{recall_score(y_test, preds, average='macro')}\")\n  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(hate_space_weights,not_hate_space_weights)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(hate_space,not_hate_space)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_bert_model(model,tokenizer,params):\n        output_dir = 'Saved/bert'\n#         if(params['train_att']):\n#             if(params['lambda_attn']>=1):\n#                 params['lambda_attn']=int(params['lambda_attn'])\n\n#             output_dir =  output_dir+str(params['supervised_layer_pos'])+'_'+str(params['num_supervised_heads'])+'_'+str(params['num_classes'])+'_'+str(params['lambda_attn'])+'/'\n            \n#         else:\n#             output_dir=output_dir+'_'+str(params['num_classes'])+'/'\n#         print(output_dir)\n#         # Create output directory if needed\n#         if not os.path.exists(output_dir):\n#             os.makedirs(output_dir)\n\n#         print(\"Saving model to %s\" % output_dir)\n\n        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n        # They can then be reloaded using `from_pretrained()`\n        model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n        model_to_save.save_pretrained(output_dir)\n        tokenizer.save_pretrained(output_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_bert_model(model,tokenizer,model.parameters())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(hate_space, 'hatespace.pt')\ntorch.save(hate_space_weights, 'hatespace.pt_weights')\ntorch.save(not_hate_space, 'not_hatespace.pt')\ntorch.save(not_hate_space_weights, 'not_hatespace_weights.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}