{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9332884,"sourceType":"datasetVersion","datasetId":5655079},{"sourceId":9577734,"sourceType":"datasetVersion","datasetId":5839090},{"sourceId":9618541,"sourceType":"datasetVersion","datasetId":5870174}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\nfrom torch import nn\nimport numpy as np \ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Import torch.nn.functional as F\nimport torch.nn.functional as F\nimport os\n\n# Set your API key here\nos.environ[\"WANDB_API_KEY\"] = \"5e8d06e5ae60a39c7945e42203c69152c47dbb61\"\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T08:37:11.702634Z","iopub.execute_input":"2024-10-18T08:37:11.703055Z","iopub.status.idle":"2024-10-18T08:37:11.709359Z","shell.execute_reply.started":"2024-10-18T08:37:11.703018Z","shell.execute_reply":"2024-10-18T08:37:11.708053Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install transformers\n!pip install rouge-score\n!pip install sacrebleu\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T08:37:15.769708Z","iopub.execute_input":"2024-10-18T08:37:15.770836Z","iopub.status.idle":"2024-10-18T08:37:58.428545Z","shell.execute_reply.started":"2024-10-18T08:37:15.770763Z","shell.execute_reply":"2024-10-18T08:37:58.426932Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=994974cf2d95d9bc20937b22b7ddcaef0b3242c7ce962b43deb8f7b63683ef4d\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score\nSuccessfully installed rouge-score-0.1.2\nCollecting sacrebleu\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2024.5.15)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\nDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-2.10.1 sacrebleu-2.4.3\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"data_path = \"/kaggle/input/pcmag-dataset/train.csv\"\ntest_path=\"/kaggle/input/pcmag-dataset/test.csv\"\nvalid_path=\"/kaggle/input/pcmag-dataset/valid.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-10-18T08:38:17.375012Z","iopub.execute_input":"2024-10-18T08:38:17.375477Z","iopub.status.idle":"2024-10-18T08:38:17.381578Z","shell.execute_reply.started":"2024-10-18T08:38:17.375437Z","shell.execute_reply":"2024-10-18T08:38:17.380316Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"output_dir_positive = \"/kaggle/working/checkpoints/negative\"","metadata":{"execution":{"iopub.status.busy":"2024-10-18T08:38:19.179664Z","iopub.execute_input":"2024-10-18T08:38:19.180123Z","iopub.status.idle":"2024-10-18T08:38:19.185851Z","shell.execute_reply.started":"2024-10-18T08:38:19.180082Z","shell.execute_reply":"2024-10-18T08:38:19.184404Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv(data_path)\ndf = pd.DataFrame(data).fillna(\"NONE\")\nprint(df.columns)\ndata = pd.read_csv(test_path)\ntf = pd.DataFrame(data).fillna(\"NONE\")\ndata = pd.read_csv(valid_path)\nvf = pd.DataFrame(data).fillna(\"NONE\")","metadata":{"execution":{"iopub.status.busy":"2024-10-18T08:38:23.807865Z","iopub.execute_input":"2024-10-18T08:38:23.808313Z","iopub.status.idle":"2024-10-18T08:38:26.674118Z","shell.execute_reply.started":"2024-10-18T08:38:23.808271Z","shell.execute_reply":"2024-10-18T08:38:26.672911Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Index(['product_name', 'overall_rating', 'review_text', 'positive_comment',\n       'negative_comment', 'neural_comment'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Convert the 'price' column to numeric, invalid parsing will be set as NaN\ndef is_numeric(value):\n    try:\n        float(value)\n        return True\n    except ValueError:\n        return False \ndf=df.fillna('None')\ndf = df[df[\"overall_rating\"].apply(is_numeric)]\ntf=tf[tf[\"overall_rating\"].apply(is_numeric)]\nvf=vf[vf[\"overall_rating\"].apply(is_numeric)]\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T08:38:28.995172Z","iopub.execute_input":"2024-10-18T08:38:28.995587Z","iopub.status.idle":"2024-10-18T08:38:29.031234Z","shell.execute_reply.started":"2024-10-18T08:38:28.995548Z","shell.execute_reply":"2024-10-18T08:38:29.029964Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"df['overall_rating'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-10-18T08:38:33.605744Z","iopub.execute_input":"2024-10-18T08:38:33.606219Z","iopub.status.idle":"2024-10-18T08:38:33.620322Z","shell.execute_reply.started":"2024-10-18T08:38:33.606175Z","shell.execute_reply":"2024-10-18T08:38:33.618933Z"},"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"array([4. , 3.5, 3. , 4.5, 5. , 2.5, 2. , 1.5, 1. , 0. ])"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\npossible_ratings = [i * 0.5 for i in range(11)] \nencoder = OneHotEncoder(sparse=False)\nencoded_df = pd.get_dummies(df['overall_rating'], prefix='rating').reindex(columns=[f'rating_{r}' for r in possible_ratings], fill_value=0)\ndf = pd.concat([df, encoded_df], axis=1)\nencoded_tf = pd.get_dummies(tf['overall_rating'], prefix='rating').reindex(columns=[f'rating_{r}' for r in possible_ratings], fill_value=0)\ntf = pd.concat([tf, encoded_tf], axis=1)\n\n# For vf (validation data)\nencoded_vf = pd.get_dummies(vf['overall_rating'], prefix='rating').reindex(columns=[f'rating_{r}' for r in possible_ratings], fill_value=0)\nvf = pd.concat([vf, encoded_vf], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-10-18T08:38:37.801364Z","iopub.execute_input":"2024-10-18T08:38:37.801803Z","iopub.status.idle":"2024-10-18T08:38:37.825889Z","shell.execute_reply.started":"2024-10-18T08:38:37.801766Z","shell.execute_reply":"2024-10-18T08:38:37.824883Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"print(df.columns)\nprint(vf.columns)\nprint(vf.columns)","metadata":{"execution":{"iopub.status.busy":"2024-10-18T08:38:40.667736Z","iopub.execute_input":"2024-10-18T08:38:40.668149Z","iopub.status.idle":"2024-10-18T08:38:40.674854Z","shell.execute_reply.started":"2024-10-18T08:38:40.668112Z","shell.execute_reply":"2024-10-18T08:38:40.673566Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Index(['product_name', 'overall_rating', 'review_text', 'positive_comment',\n       'negative_comment', 'neural_comment', 'rating_0.0', 'rating_0.5',\n       'rating_1.0', 'rating_1.5', 'rating_2.0', 'rating_2.5', 'rating_3.0',\n       'rating_3.5', 'rating_4.0', 'rating_4.5', 'rating_5.0'],\n      dtype='object')\nIndex(['product_name', 'overall_rating', 'review_text', 'positive_comment',\n       'negative_comment', 'neural_comment', 'rating_0.0', 'rating_0.5',\n       'rating_1.0', 'rating_1.5', 'rating_2.0', 'rating_2.5', 'rating_3.0',\n       'rating_3.5', 'rating_4.0', 'rating_4.5', 'rating_5.0'],\n      dtype='object')\nIndex(['product_name', 'overall_rating', 'review_text', 'positive_comment',\n       'negative_comment', 'neural_comment', 'rating_0.0', 'rating_0.5',\n       'rating_1.0', 'rating_1.5', 'rating_2.0', 'rating_2.5', 'rating_3.0',\n       'rating_3.5', 'rating_4.0', 'rating_4.5', 'rating_5.0'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Define custom dataset class\nclass Custom_Dataset(torch.utils.data.Dataset):\n    def __init__(self, data,pgen,ngen,nut_gen, labels):\n        self.data = data\n        self.positive_gen=pgen\n        self.negative_gen=ngen\n        self.neutral_gen=nut_gen\n        self.labels = labels\n        \n    def __getitem__(self, index: int) -> (torch.Tensor,torch.Tensor,torch.Tensor,torch.Tensor, list):\n        x = self.data[index]\n        pgen=self.positive_gen\n        ngen=self.negative_gen\n        nut_gen=self.neutral_gen\n        y = self.labels[index]\n        return (x,pgen,ngen,nut_gen, y)\n    \n    def __len__(self) -> int:\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2024-10-18T08:38:43.475713Z","iopub.execute_input":"2024-10-18T08:38:43.476137Z","iopub.status.idle":"2024-10-18T08:38:43.484064Z","shell.execute_reply.started":"2024-10-18T08:38:43.476099Z","shell.execute_reply":"2024-10-18T08:38:43.482791Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# X_train, X_test, y_train, y_test = train_test_split(df[['review_text']], df[['overall_rating', 'positive_comment',\n#        'negative_comment', 'neural_comment', 'overall_rating_0.0',\n#        'overall_rating_1.0', 'overall_rating_1.5', 'overall_rating_2.0',\n#        'overall_rating_2.5', 'overall_rating_3.0', 'overall_rating_3.5',\n#        'overall_rating_4.0', 'overall_rating_4.5', 'overall_rating_5.0']], test_size=0.2, shuffle=True)\n\n# # Define train and test datasets and dataloaders\n# # data,pgen,ngen,nut_gen, labels\ntrain_data = Custom_Dataset(data=df['review_text'],pgen=df['positive_comment'],ngen=df['negative_comment'],nut_gen=df['neural_comment'],labels=df[[ 'rating_0.0', 'rating_0.5',\n       'rating_1.0', 'rating_1.5', 'rating_2.0', 'rating_2.5', 'rating_3.0',\n       'rating_3.5', 'rating_4.0', 'rating_4.5', 'rating_5.0']])\ntest_data = Custom_Dataset(data=tf['review_text'],pgen=tf['positive_comment'],ngen=tf['negative_comment'],nut_gen=tf['neural_comment'],labels=tf[['rating_0.0', 'rating_0.5',\n       'rating_1.0', 'rating_1.5', 'rating_2.0', 'rating_2.5', 'rating_3.0',\n       'rating_3.5', 'rating_4.0', 'rating_4.5', 'rating_5.0']])\nvalid_data = Custom_Dataset(data=vf['review_text'],pgen=vf['positive_comment'],ngen=vf['negative_comment'],nut_gen=vf['neural_comment'],labels=vf[['rating_0.0', 'rating_0.5',\n       'rating_1.0', 'rating_1.5', 'rating_2.0', 'rating_2.5', 'rating_3.0',\n       'rating_3.5', 'rating_4.0', 'rating_4.5', 'rating_5.0']])\ntrain_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=3, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=1, shuffle=False)\ntest_loader = torch.utils.data.DataLoader(dataset=valid_data, batch_size=1, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-18T08:38:46.543085Z","iopub.execute_input":"2024-10-18T08:38:46.543560Z","iopub.status.idle":"2024-10-18T08:38:46.574696Z","shell.execute_reply.started":"2024-10-18T08:38:46.543488Z","shell.execute_reply":"2024-10-18T08:38:46.573575Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import transformers\nfrom datasets import Dataset\nfrom datasets import load_dataset, load_metric, load_from_disk\nmetric = load_metric('rouge',trust_remote_code=True)\nmodel_checkpoints = 'facebook/bart-large-xsum'\n# Check if CUDA is available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T08:38:49.608625Z","iopub.execute_input":"2024-10-18T08:38:49.609084Z","iopub.status.idle":"2024-10-18T08:38:51.671516Z","shell.execute_reply.started":"2024-10-18T08:38:49.609042Z","shell.execute_reply":"2024-10-18T08:38:51.670314Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3103988912.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n  metric = load_metric('rouge',trust_remote_code=True)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09fae4f4996745d39fce566b066cfc77"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from transformers import BartTokenizer, BartForConditionalGeneration, Trainer, TrainingArguments\nfrom datasets import Dataset\nimport torch\n\n# Check if CUDA is available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntokenizer = transformers.AutoTokenizer.from_pretrained(model_checkpoints)\ndef preprocess_data_negative(df):\n  #get the dialogue text\n  inputs = [(\"negative summary of \"+dialogue) for dialogue in df['review_text']]\n  #tokenize text\n  model_inputs = tokenizer(inputs,  max_length=1024, padding='max_length', truncation=True)\n\n  #tokenize labels\n  with tokenizer.as_target_tokenizer():\n    targets = tokenizer(df['negative_comment'], max_length=512, padding='max_length', truncation=True)\n    \n  model_inputs['labels'] = targets['input_ids']\n  #reuturns input_ids, attention_masks, labels\n  return model_inputs\ndef preprocess_data_positive(df):\n  #get the dialogue text\n  inputs = [(\"positive summary of \"+dialogue) for dialogue in df['review_text']]\n  #tokenize text\n  model_inputs = tokenizer(inputs,  max_length=1024, padding='max_length', truncation=True)\n\n  #tokenize labels\n  with tokenizer.as_target_tokenizer():\n    targets = tokenizer(df['positive_comment'], max_length=512, padding='max_length', truncation=True)\n    \n  model_inputs['labels'] = targets['input_ids']\n  #reuturns input_ids, attention_masks, labels\n  return model_inputs\ndef preprocess_data_neutral(df):\n  #get the dialogue text\n  inputs = [(\"neural summary of \"+dialogue) for dialogue in df['review_text']]\n  #tokenize text\n  model_inputs = tokenizer(inputs,  max_length=1024, padding='max_length', truncation=True)\n\n  #tokenize labels\n  with tokenizer.as_target_tokenizer():\n    targets = tokenizer(df['neural_comment'], max_length=512, padding='max_length', truncation=True)\n    \n  model_inputs['labels'] = targets['input_ids']\n  #reuturns input_ids, attention_masks, labels\n  return model_inputs\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T08:39:02.503996Z","iopub.execute_input":"2024-10-18T08:39:02.505235Z","iopub.status.idle":"2024-10-18T08:39:07.013268Z","shell.execute_reply.started":"2024-10-18T08:39:02.505185Z","shell.execute_reply":"2024-10-18T08:39:07.012066Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2c63cfd275c43d896a6fbf1c82fc32b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.51k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"644cb7a959b74aaca4551fc0f93212bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8afb7659acbf45f2a11f9097af1211cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c137805bd344593926ced7bf4fc98fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c11f2b9deeaa46b7b4065cb3f8266645"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# train_df=Dataset.from_pandas(df)\n# valid_df=Dataset.from_pandas(vf)\n# test_df=Dataset.from_pandas(tf)\n# tokenize_train = train_df.map(preprocess_data_negative, batched = True, remove_columns=[ 'review_text', 'negative_comment'])\n# tokenize_valid = valid_df.map(preprocess_data_negative, batched = True, remove_columns=[ 'review_text', 'negative_comment'])\n# tokenize_test = test_df.map(preprocess_data_negative, batched = True, remove_columns=[ 'review_text', 'negative_comment'])","metadata":{"execution":{"iopub.status.busy":"2024-10-18T08:40:23.022775Z","iopub.execute_input":"2024-10-18T08:40:23.023239Z","iopub.status.idle":"2024-10-18T08:41:09.719224Z","shell.execute_reply.started":"2024-10-18T08:40:23.023191Z","shell.execute_reply":"2024-10-18T08:41:09.718088Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13741 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17f2f25a9e56431dbae936b685dfe05c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1735 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f2961d5a8f24be591702e403948b0e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1718 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a69ceaab5f8d453985366faef7028594"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# Process each dataset separately\ntokenize_train_negative = train_df.map(preprocess_data_negative, batched=True, remove_columns=['review_text', 'negative_comment'])\ntokenize_train_positive = train_df.map(preprocess_data_positive, batched=True, remove_columns=['review_text', 'positive_comment'])\ntokenize_train_neutral = train_df.map(preprocess_data_neutral, batched=True, remove_columns=['review_text', 'neural_comment'])\n\n# Concatenate fields manually to ensure a flat structure\ndef concatenate_datasets_flat(dataset1, dataset2, dataset3):\n    concatenated_dataset = {\n        'input_ids': dataset1['input_ids'] + dataset2['input_ids'] + dataset3['input_ids'],\n        'attention_mask': dataset1['attention_mask'] + dataset2['attention_mask'] + dataset3['attention_mask'],\n        'labels': dataset1['labels'] + dataset2['labels'] + dataset3['labels'],\n    }\n   \n    return Dataset.from_dict(concatenated_dataset)\n\n# Concatenate the tokenized data across negative, positive, and neutral\ntokenize_train = concatenate_datasets_flat(tokenize_train_negative, tokenize_train_positive, tokenize_train_neutral)\nprint(tokenize_train.column_names)\n# Repeat the same process for validation and test sets\ntokenize_valid_negative = valid_df.map(preprocess_data_negative, batched=True, remove_columns=['review_text', 'negative_comment'])\ntokenize_valid_positive = valid_df.map(preprocess_data_positive, batched=True, remove_columns=['review_text', 'positive_comment'])\ntokenize_valid_neutral = valid_df.map(preprocess_data_neutral, batched=True, remove_columns=['review_text', 'neural_comment'])\n\ntokenize_valid = concatenate_datasets_flat(tokenize_valid_negative, tokenize_valid_positive, tokenize_valid_neutral)\n\ntokenize_test_negative = test_df.map(preprocess_data_negative, batched=True, remove_columns=['review_text', 'negative_comment'])\ntokenize_test_positive = test_df.map(preprocess_data_positive, batched=True, remove_columns=['review_text', 'positive_comment'])\ntokenize_test_neutral = test_df.map(preprocess_data_neutral, batched=True, remove_columns=['review_text', 'neural_comment'])\n\ntokenize_test = concatenate_datasets_flat(tokenize_test_negative, tokenize_test_positive, tokenize_test_neutral)\n\n# Now tokenize_train, tokenize_valid, and tokenize_test contain the combined datasets in a flat structure\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T09:07:39.567867Z","iopub.execute_input":"2024-10-18T09:07:39.568375Z","iopub.status.idle":"2024-10-18T09:11:31.743076Z","shell.execute_reply.started":"2024-10-18T09:07:39.568332Z","shell.execute_reply":"2024-10-18T09:11:31.741827Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13741 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b663705fbd614da8985fd7c95b72f669"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13741 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee47df817bb7404facc31803e0c6cbde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13741 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a0cd81057084fd98624dfa1348ba0e9"}},"metadata":{}},{"name":"stdout","text":"['input_ids', 'attention_mask', 'labels']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1735 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b64da6416d24993b0fe00106c4549c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1735 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a7d7bb5dd164d5b88ed026c998db6bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1735 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86d5e4c2f6a0485196d51dabb828bc0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1718 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"577125f776bd48b8b86f319c1f6046a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1718 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca74e8287c9e42b1be1d4e8a8d4a3c96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1718 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81f0a7ad9dfe4280852f50c6519f2c4e"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"tokenize_train.save_to_disk(\"./tokenized_dataset/train/checkpoint\")\ntokenize_valid.save_to_disk(\"./tokenized_dataset/valid/checkpoint\")\ntokenize_test.save_to_disk(\"./tokenized_dataset/test/checkpoint\")\n# tokenized_train = load_from_disk(\"./tokenized_dataset/train/checkpoint\")\n# tokenized_valid = load_from_disk(\"./tokenized_dataset/valid/checkpoint\")\n# tokenized_test = load_from_disk(\"./tokenized_dataset/test/checkpoint\")","metadata":{"execution":{"iopub.status.busy":"2024-10-16T08:43:29.036235Z","iopub.execute_input":"2024-10-16T08:43:29.036856Z","iopub.status.idle":"2024-10-16T08:43:29.705274Z","shell.execute_reply.started":"2024-10-16T08:43:29.036805Z","shell.execute_reply":"2024-10-16T08:43:29.703916Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = transformers.AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints).to(device)\n#collator to create batches. It preprocess data with the given tokenizer\ncollator = transformers.DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2024-10-18T09:16:17.273629Z","iopub.execute_input":"2024-10-18T09:16:17.274449Z","iopub.status.idle":"2024-10-18T09:17:11.825815Z","shell.execute_reply.started":"2024-10-18T09:16:17.274403Z","shell.execute_reply":"2024-10-18T09:17:11.824787Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3ddf5bf084448b9903e1c64ba960635"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/309 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2ce635a113a4af1aeadc1d5548dfbb4"}},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# print(df.columns)\n# df[\"negative_comment\"].head()\ndef compute_rouge(pred):\n  predictions, labels = pred\n  #decode the predictions\n  decode_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n  #decode labels\n  decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n  #compute results\n  res = metric.compute(predictions=decode_predictions, references=decode_labels, use_stemmer=True)\n  #get %\n  res = {key: value.mid.fmeasure * 100 for key, value in res.items()}\n\n  pred_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n  res['gen_len'] = np.mean(pred_lens)\n\n  return {k: round(v, 4) for k, v in res.items()}","metadata":{"execution":{"iopub.status.busy":"2024-10-18T09:33:44.704815Z","iopub.execute_input":"2024-10-18T09:33:44.705367Z","iopub.status.idle":"2024-10-18T09:33:44.715886Z","shell.execute_reply.started":"2024-10-18T09:33:44.705322Z","shell.execute_reply":"2024-10-18T09:33:44.714618Z"},"trusted":true},"outputs":[],"execution_count":27},{"cell_type":"code","source":"args = transformers.Seq2SeqTrainingArguments(\n    evaluation_strategy='epoch',  # Your current evaluation strategy\n    save_strategy='epoch',        # Set save strategy to match evaluation strategy\n    learning_rate=2e-5,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=5,\n    predict_with_generate=True,\n    eval_accumulation_steps=1,\n    fp16=True,\n    load_best_model_at_end=True,\n    output_dir=output_dir_positive,\n    resume_from_checkpoint=True\n)\n\ntrainer = transformers.Seq2SeqTrainer(\n    model, \n    args,\n    train_dataset=tokenize_train,\n    eval_dataset=tokenize_valid,\n    data_collator=collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_rouge\n)\ntrainer.train()\n\nmodel.save_pretrained(\"./fine_tuned_model_negative\")\n\n# Save the tokenizer\ntokenizer.save_pretrained(\"./fine_tuned_model_nagative\")","metadata":{"execution":{"iopub.status.busy":"2024-10-18T09:33:52.731251Z","iopub.execute_input":"2024-10-18T09:33:52.731722Z","iopub.status.idle":"2024-10-18T09:34:53.005117Z","shell.execute_reply.started":"2024-10-18T09:33:52.731678Z","shell.execute_reply":"2024-10-18T09:34:53.003411Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2' max='103055' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [     2/103055 : < :, Epoch 0.00/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 28\u001b[0m\n\u001b[1;32m      1\u001b[0m args \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mSeq2SeqTrainingArguments(\n\u001b[1;32m      2\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Your current evaluation strategy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     save_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m,        \u001b[38;5;66;03m# Set save strategy to match evaluation strategy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     resume_from_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m trainer \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mSeq2SeqTrainer(\n\u001b[1;32m     20\u001b[0m     model, \n\u001b[1;32m     21\u001b[0m     args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_rouge\n\u001b[1;32m     27\u001b[0m )\n\u001b[0;32m---> 28\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./fine_tuned_model_negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Save the tokenizer\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1948\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1946\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1949\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2289\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2288\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2289\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2292\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2293\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2295\u001b[0m ):\n\u001b[1;32m   2296\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2297\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3359\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3357\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:2159\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2159\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":28}]}