{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7528128,"sourceType":"datasetVersion","datasetId":4384787}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install torch\n# !pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:51.507046Z","iopub.execute_input":"2024-03-04T13:52:51.507679Z","iopub.status.idle":"2024-03-04T13:52:51.511833Z","shell.execute_reply.started":"2024-03-04T13:52:51.507648Z","shell.execute_reply":"2024-03-04T13:52:51.510862Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Regular imports\nimport matplotlib.pyplot as plt\nimport torch\n\nfrom torch import nn\nimport numpy as np \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-04T13:52:51.514888Z","iopub.execute_input":"2024-03-04T13:52:51.515250Z","iopub.status.idle":"2024-03-04T13:52:51.525255Z","shell.execute_reply.started":"2024-03-04T13:52:51.515218Z","shell.execute_reply":"2024-03-04T13:52:51.524355Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:51.526556Z","iopub.execute_input":"2024-03-04T13:52:51.526855Z","iopub.status.idle":"2024-03-04T13:52:51.537239Z","shell.execute_reply.started":"2024-03-04T13:52:51.526832Z","shell.execute_reply":"2024-03-04T13:52:51.536393Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"data_path = \"/kaggle/input/majortry6/labeled_data.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:51.538502Z","iopub.execute_input":"2024-03-04T13:52:51.538919Z","iopub.status.idle":"2024-03-04T13:52:51.545888Z","shell.execute_reply.started":"2024-03-04T13:52:51.538868Z","shell.execute_reply":"2024-03-04T13:52:51.545025Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pickle\nimport pandas as pd\npd.options.mode.copy_on_write = True\n\ndata = pd.read_csv(data_path)\ndf = pd.DataFrame(data)\nprint(df.columns)\ndf.columns = ['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither',\n       'classk', 'tweet']","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:51.547264Z","iopub.execute_input":"2024-03-04T13:52:51.547655Z","iopub.status.idle":"2024-03-04T13:52:51.613371Z","shell.execute_reply.started":"2024-03-04T13:52:51.547621Z","shell.execute_reply":"2024-03-04T13:52:51.612492Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Index(['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither',\n       'class', 'tweet'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"df[\"classk\"] = df[\"classk\"].map({2:1, 1:0, 0:0}) \n# label = 0 = hate\n# label = 1 = not_hate","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:51.614864Z","iopub.execute_input":"2024-03-04T13:52:51.615156Z","iopub.status.idle":"2024-03-04T13:52:51.620710Z","shell.execute_reply.started":"2024-03-04T13:52:51.615130Z","shell.execute_reply":"2024-03-04T13:52:51.619713Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"tweets = df.tweet\nres = []\n\nfor i in range(len(tweets)):\n    splitt = tweets[i].split(\":\")\n    if len(splitt) == 1:\n        res.append(splitt[0])\n    else:\n        res.append(splitt[-1])\n        \ntweets = res\n\n# print(tweets)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:51.621686Z","iopub.execute_input":"2024-03-04T13:52:51.621937Z","iopub.status.idle":"2024-03-04T13:52:51.760331Z","shell.execute_reply.started":"2024-03-04T13:52:51.621905Z","shell.execute_reply":"2024-03-04T13:52:51.759580Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"hate_words = ['Moist', 'Cunt', 'Panties', 'Fuck', 'Hate', 'Nigger', 'Pussy', 'Ass', 'Motherfucker', 'Bitch', 'Damn']\nnot_hate_words = ['Love', 'Peace', 'Kindness', 'Happiness', 'Respect', 'Friendship',\n'Appreciation', 'Hope', 'Encouragement', 'Support', 'Caring']","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:51.762305Z","iopub.execute_input":"2024-03-04T13:52:51.762584Z","iopub.status.idle":"2024-03-04T13:52:51.767623Z","shell.execute_reply.started":"2024-03-04T13:52:51.762560Z","shell.execute_reply":"2024-03-04T13:52:51.766740Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"from transformers import RobertaModel, RobertaTokenizer\n\n# Load pre-trained RoBERTa model and tokenizer\nmodel_name = \"roberta-base\"\n\ntokenizer = RobertaTokenizer.from_pretrained(model_name, token=\"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\")\n\ntokenizer(\"I love Pokemon\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:51.769294Z","iopub.execute_input":"2024-03-04T13:52:51.770106Z","iopub.status.idle":"2024-03-04T13:52:52.065822Z","shell.execute_reply.started":"2024-03-04T13:52:51.770081Z","shell.execute_reply":"2024-03-04T13:52:52.064869Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [0, 100, 657, 26052, 2], 'attention_mask': [1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"model =  RobertaModel.from_pretrained(model_name)\n\ninputs = tokenizer(\"Hello my dog is cute\", return_tensors=\"pt\")\nprint(inputs)\n\noutputs = model(**inputs)\n\nprint(len(outputs.last_hidden_state[0])) # => no. of tokens + [CLS] + [SEP]\nprint(len(outputs.last_hidden_state[0][1])) # => hidden dim size\nprint(len(outputs.last_hidden_state[0][2])) # => hidden dim size","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:52.067061Z","iopub.execute_input":"2024-03-04T13:52:52.067412Z","iopub.status.idle":"2024-03-04T13:52:52.957058Z","shell.execute_reply.started":"2024-03-04T13:52:52.067380Z","shell.execute_reply":"2024-03-04T13:52:52.956037Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"{'input_ids': tensor([[    0, 31414,   127,  2335,    16, 11962,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n7\n768\n768\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs = tokenizer(\"shatterd\", return_tensors=\"pt\")\noutputs = model(**inputs)\nprint(outputs.last_hidden_state[0][1:len(outputs.last_hidden_state[0])])","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:52.958252Z","iopub.execute_input":"2024-03-04T13:52:52.958536Z","iopub.status.idle":"2024-03-04T13:52:53.013792Z","shell.execute_reply.started":"2024-03-04T13:52:52.958511Z","shell.execute_reply":"2024-03-04T13:52:53.012849Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"tensor([[-0.1097, -0.0864,  0.1443,  ..., -0.3975,  0.1201, -0.0709],\n        [ 0.1166, -0.1417, -0.0394,  ..., -0.3211, -0.1199, -0.1773],\n        [ 0.1630, -0.1101,  0.0422,  ..., -0.0305,  0.0285, -0.0697],\n        [-0.0517,  0.0818, -0.0415,  ..., -0.1247, -0.0896, -0.0421]],\n       grad_fn=<SliceBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs = tokenizer(\"shatter\", return_tensors=\"pt\")\noutputs = model(**inputs)\nprint(outputs.last_hidden_state[0][1:len(outputs.last_hidden_state[0])])","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:53.015062Z","iopub.execute_input":"2024-03-04T13:52:53.015689Z","iopub.status.idle":"2024-03-04T13:52:53.069859Z","shell.execute_reply.started":"2024-03-04T13:52:53.015658Z","shell.execute_reply":"2024-03-04T13:52:53.068797Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"tensor([[-0.0217, -0.0436,  0.0626,  ..., -0.1816,  0.0255,  0.2100],\n        [ 0.0523,  0.1572, -0.0863,  ..., -0.3361, -0.0153,  0.1608],\n        [-0.0574,  0.0975, -0.0369,  ..., -0.1255, -0.0795, -0.0347]],\n       grad_fn=<SliceBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"temp = []\n# model = BertModel.from_pretrained(\"bert-base-uncased\")\n\nfor word in hate_words:\n    inputs = tokenizer(word, return_tensors=\"pt\")\n#     print(inputs)\n    outputs = model(**inputs)\n    \n    outputs = torch.mean(outputs.last_hidden_state[0][1:len(outputs.last_hidden_state[0])], dim=0)\n    \"\"\"calculating mean of embeddings execept cls token\n    since words may be tokinized differently like (motherF***)=>(mother,F***)\n    we take average of those embeddings to represent each word \"\"\"\n    temp.append(outputs.tolist())\n\n\nhate_space =torch.tensor(temp).to(device).requires_grad_()\n\nhate_space.is_leaf\nhate_space.dtype\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:53.071037Z","iopub.execute_input":"2024-03-04T13:52:53.071336Z","iopub.status.idle":"2024-03-04T13:52:53.556040Z","shell.execute_reply.started":"2024-03-04T13:52:53.071309Z","shell.execute_reply":"2024-03-04T13:52:53.555061Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"torch.float32"},"metadata":{}}]},{"cell_type":"code","source":"hate_space.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:53.560170Z","iopub.execute_input":"2024-03-04T13:52:53.560583Z","iopub.status.idle":"2024-03-04T13:52:53.568669Z","shell.execute_reply.started":"2024-03-04T13:52:53.560550Z","shell.execute_reply":"2024-03-04T13:52:53.567623Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"torch.Size([11, 768])"},"metadata":{}}]},{"cell_type":"code","source":"temp = []\n\nfor word in not_hate_words:\n    inputs = tokenizer(word, return_tensors=\"pt\")\n\n    outputs = model(**inputs)\n    outputs = torch.mean(outputs.last_hidden_state[0][1:len(outputs.last_hidden_state[0])], dim=0)\n    temp.append(outputs.tolist())\n\nnot_hate_space = torch.tensor(temp).to(device).requires_grad_()\n\nprint(not_hate_space.is_leaf)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:53.569963Z","iopub.execute_input":"2024-03-04T13:52:53.570302Z","iopub.status.idle":"2024-03-04T13:52:54.054856Z","shell.execute_reply.started":"2024-03-04T13:52:53.570276Z","shell.execute_reply":"2024-03-04T13:52:54.053842Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"code","source":"# Trial matmul\n\nt1 = torch.randn(11, 768)\nt2 = torch.randn(4, 23, 768)\n\nprint(torch.transpose(t2, 1, 2).shape)\n\ntorch.matmul(t1, torch.transpose(t2, 1, 2)).shape","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:54.056073Z","iopub.execute_input":"2024-03-04T13:52:54.056365Z","iopub.status.idle":"2024-03-04T13:52:54.066691Z","shell.execute_reply.started":"2024-03-04T13:52:54.056340Z","shell.execute_reply":"2024-03-04T13:52:54.065652Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"torch.Size([4, 768, 23])\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 11, 23])"},"metadata":{}}]},{"cell_type":"code","source":"print(\"hate_space.grad:\", hate_space.grad)\nprint(\"not_hate_space.grad:\", not_hate_space.grad)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:54.068026Z","iopub.execute_input":"2024-03-04T13:52:54.068312Z","iopub.status.idle":"2024-03-04T13:52:54.074404Z","shell.execute_reply.started":"2024-03-04T13:52:54.068286Z","shell.execute_reply":"2024-03-04T13:52:54.073330Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"hate_space.grad: None\nnot_hate_space.grad: None\n","output_type":"stream"}]},{"cell_type":"code","source":"class Custom_Dataset(torch.utils.data.Dataset):\n    \n    def __init__(self, data, labels):\n        self.data = data\n        self.labels = labels\n        \n    def __getitem__(self, index: int) -> (torch.Tensor, int): # => (X, y)\n        \n        X = self.data[index]\n        y = self.labels[index]\n\n        return (X, y)\n    \n    \n    def __len__(self) -> int:\n        \n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:54.075982Z","iopub.execute_input":"2024-03-04T13:52:54.076293Z","iopub.status.idle":"2024-03-04T13:52:54.084454Z","shell.execute_reply.started":"2024-03-04T13:52:54.076266Z","shell.execute_reply":"2024-03-04T13:52:54.083576Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(tweets, list(df.classk), test_size=0.2, shuffle=True)\n\nprint(len(X_train), len(y_train))\nprint(len(X_test), len(y_test))","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:54.085607Z","iopub.execute_input":"2024-03-04T13:52:54.085901Z","iopub.status.idle":"2024-03-04T13:52:54.112644Z","shell.execute_reply.started":"2024-03-04T13:52:54.085876Z","shell.execute_reply":"2024-03-04T13:52:54.111727Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"19826 19826\n4957 4957\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = Custom_Dataset(data=X_train, labels=y_train)\ntest_data = Custom_Dataset(data=X_test, labels=y_test)\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=3, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:54.113693Z","iopub.execute_input":"2024-03-04T13:52:54.113971Z","iopub.status.idle":"2024-03-04T13:52:54.122003Z","shell.execute_reply.started":"2024-03-04T13:52:54.113947Z","shell.execute_reply":"2024-03-04T13:52:54.121052Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"import random\nl=[[random.uniform(-1,1)] for i in range(11)]\nl","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:54.123215Z","iopub.execute_input":"2024-03-04T13:52:54.123807Z","iopub.status.idle":"2024-03-04T13:52:54.132454Z","shell.execute_reply.started":"2024-03-04T13:52:54.123776Z","shell.execute_reply":"2024-03-04T13:52:54.131489Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"[[-0.9730272007670802],\n [0.8358091393459206],\n [-0.14008327768198559],\n [0.8846264231614258],\n [0.5164325705426474],\n [-0.3419881549537507],\n [-0.49921674328742127],\n [-0.047478615764504184],\n [-0.42660397772583236],\n [-0.37187613158194877],\n [-0.6439363544080858]]"},"metadata":{}}]},{"cell_type":"code","source":"# next(iter(test_loader)) \ntensor_shape = (11,1)\nhate_space_weights = torch.tensor(l).to(device).requires_grad_()\nnot_hate_space_weights = torch.tensor(l).to(device).requires_grad_()\n\nprint(hate_space_weights.device,not_hate_space_weights.is_leaf)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:54.133558Z","iopub.execute_input":"2024-03-04T13:52:54.133877Z","iopub.status.idle":"2024-03-04T13:52:54.142733Z","shell.execute_reply.started":"2024-03-04T13:52:54.133853Z","shell.execute_reply":"2024-03-04T13:52:54.141712Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"cuda:0 True\n","output_type":"stream"}]},{"cell_type":"code","source":"hate_space_weights.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:54.143828Z","iopub.execute_input":"2024-03-04T13:52:54.144502Z","iopub.status.idle":"2024-03-04T13:52:54.151482Z","shell.execute_reply.started":"2024-03-04T13:52:54.144469Z","shell.execute_reply":"2024-03-04T13:52:54.150640Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"torch.Size([11, 1])"},"metadata":{}}]},{"cell_type":"code","source":"hate_space_weights.is_leaf","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:54.152542Z","iopub.execute_input":"2024-03-04T13:52:54.152833Z","iopub.status.idle":"2024-03-04T13:52:54.161430Z","shell.execute_reply.started":"2024-03-04T13:52:54.152810Z","shell.execute_reply":"2024-03-04T13:52:54.160635Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass Model0(nn.Module):\n\n    def __init__(self, model, tokenizer):\n        super().__init__()\n        self.tokenizer = tokenizer\n        self.model = model\n\n    def forward(self, X):\n        inputs = self.tokenizer(X, return_tensors=\"pt\").to(device)\n        outputs = self.model(**inputs)\n        outputs = outputs.last_hidden_state[0][1:len(outputs.last_hidden_state[0])].transpose(0, 1)\n        print(\"outputes from bert model\",outputs.shape)\n        col_norms = torch.norm(outputs, p=2, dim=0, keepdim=True)\n        outputs = outputs / col_norms\n        \"\"\"taking norms early because if we take norms and divide each vector \n        with norm we get unit vectors without altreing direction which will be \n        same as dividing with norms after multiplication \n        similarly for hate and not_hate space.\n        indeed it doesnt alter results of model it just simplifies the model \"\"\"\n#         print(\"outputes from bert model\",outputs.shape)\n        hate_att_scores=torch.matmul(hate_space/torch.norm(hate_space,p=2, dim=0, keepdim=True),outputs)\n        not_hate_att_scores=torch.matmul(not_hate_space/torch.norm(not_hate_space,p=2, dim=0, keepdim=True),outputs)\n#         print(hate_att_scores.mean(1).shape)\n        Psk_hate = torch.matmul(hate_att_scores.mean(1), hate_space_weights)\n        Psk_not_hate = torch.matmul(not_hate_att_scores.mean(1), not_hate_space_weights)\n#         print(f\"printing Psk_hate={Psk_hate} shape={Psk_hate.shape} and Psk_not_hate={Psk_not_hate} shape={Psk_not_hate.shape}\")\n        \n        output_tensor = torch.cat((Psk_hate, Psk_not_hate), dim=0).requires_grad_()\n\n        return output_tensor\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:54.162475Z","iopub.execute_input":"2024-03-04T13:52:54.162857Z","iopub.status.idle":"2024-03-04T13:52:54.173949Z","shell.execute_reply.started":"2024-03-04T13:52:54.162822Z","shell.execute_reply":"2024-03-04T13:52:54.172993Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"mathematically\n**a.b/|a||b|=^a.^b**\n\n**a.(b+c+d)=a.b+a.c+a.d**","metadata":{}},{"cell_type":"code","source":"model0 = Model0(model, tokenizer)\n\n# X, y = next(iter(train_loader))\n# Psk_hate, Psk_not_hate = model0(X)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:54.175129Z","iopub.execute_input":"2024-03-04T13:52:54.175539Z","iopub.status.idle":"2024-03-04T13:52:54.188609Z","shell.execute_reply.started":"2024-03-04T13:52:54.175515Z","shell.execute_reply":"2024-03-04T13:52:54.187777Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Semi-SSM","metadata":{}},{"cell_type":"code","source":"def L_inter(spaces):\n    \"\"\"this function calculates inter space losses between spaces \n    forces the class spaces of different class to move apart\n    \"\"\"\n    means = [torch.mean(spaces[i]) for i in range(spaces.shape[0])]\n    \n    loss = torch.tensor(0.0, requires_grad=True)\n    \n    for k in range(len(means)):\n        cur = torch.tensor(0.0, requires_grad=True)\n        for l in range(len(means)):\n            if l == k:\n                continue\n            cur = cur + (1 / (1 - ((means[k] * means[l]))))\n        \n        loss = loss + cur\n    \n    return loss\n            \n            \n\ndef L_intra(spaces):\n    \"\"\"\"this function calculates intra space loss \nforces the vector representations inside a class space to have high variability(varience)\n\"\"\"\n    loss=torch.tensor(0.0, requires_grad=True)\n    for k in range(len(spaces)):\n        loss=loss+1/torch.var(spaces[k], dim=0)\n    \n    return torch.sum(loss)/loss.shape[0]\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:54.189812Z","iopub.execute_input":"2024-03-04T13:52:54.190106Z","iopub.status.idle":"2024-03-04T13:52:54.198882Z","shell.execute_reply.started":"2024-03-04T13:52:54.190064Z","shell.execute_reply":"2024-03-04T13:52:54.198065Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"L_inter(torch.concat((torch.tensor([[0.33, 0.54, 0.37], [0.72, 0.74, 0.31], [0.61, 0.26, 0.56]], dtype=torch.float32), \n       torch.tensor([[0.22, 0.32, 0.15], [0.12, -0.08, 0.45], [0.14, 0.28, -0.11]], dtype=torch.float32))))","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:54.200219Z","iopub.execute_input":"2024-03-04T13:52:54.200793Z","iopub.status.idle":"2024-03-04T13:52:54.216475Z","shell.execute_reply.started":"2024-03-04T13:52:54.200761Z","shell.execute_reply":"2024-03-04T13:52:54.215485Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"tensor(33.6994, grad_fn=<AddBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"print(hate_space,not_hate_space)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:54.217646Z","iopub.execute_input":"2024-03-04T13:52:54.217927Z","iopub.status.idle":"2024-03-04T13:52:54.227857Z","shell.execute_reply.started":"2024-03-04T13:52:54.217903Z","shell.execute_reply":"2024-03-04T13:52:54.226977Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"tensor([[-0.0310,  0.1629,  0.0097,  ..., -0.0019,  0.0305, -0.0738],\n        [-0.0411,  0.0255, -0.0069,  ..., -0.3014, -0.0704, -0.0058],\n        [ 0.0085,  0.0397,  0.0388,  ..., -0.1430,  0.0385,  0.0430],\n        ...,\n        [-0.1312, -0.0045, -0.0484,  ..., -0.2071, -0.0556, -0.0245],\n        [-0.0346,  0.1688,  0.0396,  ..., -0.2303, -0.1220,  0.0037],\n        [-0.0049,  0.0358,  0.0281,  ..., -0.1855, -0.0979, -0.0800]],\n       device='cuda:0', requires_grad=True) tensor([[-0.0039,  0.0822,  0.0470,  ..., -0.0254, -0.0671, -0.0814],\n        [ 0.0216,  0.1387,  0.0708,  ..., -0.1220, -0.0591, -0.0006],\n        [-0.1839,  0.1045,  0.1317,  ...,  0.1253, -0.0803,  0.0557],\n        ...,\n        [-0.0444,  0.0534,  0.0910,  ...,  0.1400,  0.0228, -0.0028],\n        [-0.1128,  0.0228,  0.0920,  ...,  0.0764, -0.0988,  0.0147],\n        [-0.0823,  0.0630,  0.0675,  ..., -0.0101, -0.0605,  0.0270]],\n       device='cuda:0', requires_grad=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(hate_space_weights,not_hate_space_weights)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:54.228932Z","iopub.execute_input":"2024-03-04T13:52:54.229434Z","iopub.status.idle":"2024-03-04T13:52:54.236719Z","shell.execute_reply.started":"2024-03-04T13:52:54.229402Z","shell.execute_reply":"2024-03-04T13:52:54.235795Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"tensor([[-0.9730],\n        [ 0.8358],\n        [-0.1401],\n        [ 0.8846],\n        [ 0.5164],\n        [-0.3420],\n        [-0.4992],\n        [-0.0475],\n        [-0.4266],\n        [-0.3719],\n        [-0.6439]], device='cuda:0', requires_grad=True) tensor([[-0.9730],\n        [ 0.8358],\n        [-0.1401],\n        [ 0.8846],\n        [ 0.5164],\n        [-0.3420],\n        [-0.4992],\n        [-0.0475],\n        [-0.4266],\n        [-0.3719],\n        [-0.6439]], device='cuda:0', requires_grad=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"model0.to(device)\n\nprint(hate_space.is_leaf)\noptimizer = torch.optim.Adam(params=[hate_space, not_hate_space, hate_space_weights, not_hate_space_weights], lr=0.01)\nmodel0.train()\n\nmodel0.train()\n\ncur=0.1\nprev=0\npprev=0\nfor _ in range(3) :\n    for i, batch in enumerate(train_loader):\n#         if i == 1:\n#             break\n        if i % 2000 == 0:\n            print(i)\n\n        x, Y = batch\n        loss = 0\n\n        for X, y in zip(x, Y):\n            y_preds = model0(X)\n#             print(y_preds)\n            print(f\"printing y_preds={y_preds} shape={y_preds.shape}\")\n\n            loss+=F.cross_entropy(y_preds.view(1, -1).to(device), torch.tensor([y]).to(device))\n            \"\"\"explisit soft max is not used to convert to probs is cross \n            entrophy loss has inbuilt softmax  function adding softmax explisity\n            will effect adversly by smoothing again on smoothed values will decrese \n            the weightage for class with high prob \"\"\"\n#             break\n        loss /= len(x)\n        loss += 1*L_inter(torch.cat((hate_space, not_hate_space))) + 1*L_intra(torch.stack([hate_space, not_hate_space]))\n            \n        optimizer.zero_grad()\n        \n        loss.backward()\n        optimizer.step()\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:52:54.237814Z","iopub.execute_input":"2024-03-04T13:52:54.238339Z","iopub.status.idle":"2024-03-04T13:53:01.065518Z","shell.execute_reply.started":"2024-03-04T13:52:54.238315Z","shell.execute_reply":"2024-03-04T13:53:01.063770Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"True\n0\noutputes from bert model torch.Size([768, 36])\noutputes from bert model torch.Size([768, 36])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.8119], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-0.6058], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.8119, -0.6058], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 12])\noutputes from bert model torch.Size([768, 12])\ntorch.Size([11])\nprinting Psk_hate=tensor([-1.1301], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-0.7485], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-1.1301, -0.7485], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 28])\noutputes from bert model torch.Size([768, 28])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.9262], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-0.9204], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.9262, -0.9204], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 17])\noutputes from bert model torch.Size([768, 17])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.6366], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-0.6869], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.6366, -0.6869], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 12])\noutputes from bert model torch.Size([768, 12])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.6343], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-0.6446], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.6343, -0.6446], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 10])\noutputes from bert model torch.Size([768, 10])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.4632], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.4189], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.4632, -1.4189], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 9])\noutputes from bert model torch.Size([768, 9])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.8354], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.0174], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.8354, -1.0174], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 19])\noutputes from bert model torch.Size([768, 19])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.4597], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-0.6927], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.4597, -0.6927], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 12])\noutputes from bert model torch.Size([768, 12])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.3666], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-0.8170], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.3666, -0.8170], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 18])\noutputes from bert model torch.Size([768, 18])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.5116], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-0.7385], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.5116, -0.7385], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 13])\noutputes from bert model torch.Size([768, 13])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.3764], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-0.7872], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.3764, -0.7872], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 20])\noutputes from bert model torch.Size([768, 20])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.3343], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-0.8656], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.3343, -0.8656], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 52])\noutputes from bert model torch.Size([768, 52])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.2662], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.0641], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.2662, -1.0641], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 15])\noutputes from bert model torch.Size([768, 15])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.3767], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-0.6781], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.3767, -0.6781], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 34])\noutputes from bert model torch.Size([768, 34])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.3554], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-0.9464], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.3554, -0.9464], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 63])\noutputes from bert model torch.Size([768, 63])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.0074], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.1349], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.0074, -1.1349], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 33])\noutputes from bert model torch.Size([768, 33])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.1815], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.0843], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.1815, -1.0843], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 35])\noutputes from bert model torch.Size([768, 35])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.2032], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.2211], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.2032, -1.2211], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 15])\noutputes from bert model torch.Size([768, 15])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.2938], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-0.9618], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.2938, -0.9618], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 7])\noutputes from bert model torch.Size([768, 7])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.0653], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.4093], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.0653, -1.4093], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 18])\noutputes from bert model torch.Size([768, 18])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.1200], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.1906], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.1200, -1.1906], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 15])\noutputes from bert model torch.Size([768, 15])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.0237], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.2521], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.0237, -1.2521], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 15])\noutputes from bert model torch.Size([768, 15])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.2022], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.5748], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.2022, -1.5748], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 25])\noutputes from bert model torch.Size([768, 25])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.0568], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-0.9959], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.0568, -0.9959], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 21])\noutputes from bert model torch.Size([768, 21])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.1197], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-0.9955], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.1197, -0.9955], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 10])\noutputes from bert model torch.Size([768, 10])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.0970], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.0730], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.0970, -1.0730], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 11])\noutputes from bert model torch.Size([768, 11])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.3251], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.2969], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.3251, -1.2969], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 6])\noutputes from bert model torch.Size([768, 6])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.0700], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.3375], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.0700, -1.3375], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 33])\noutputes from bert model torch.Size([768, 33])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.0026], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.1448], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.0026, -1.1448], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 13])\noutputes from bert model torch.Size([768, 13])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.0478], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.5019], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.0478, -1.5019], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 35])\noutputes from bert model torch.Size([768, 35])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.1801], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.4110], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.1801, -1.4110], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 34])\noutputes from bert model torch.Size([768, 34])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.1601], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.1913], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.1601, -1.1913], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 44])\noutputes from bert model torch.Size([768, 44])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.3657], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.7202], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.3657, -1.7202], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 29])\noutputes from bert model torch.Size([768, 29])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.2137], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.3258], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.2137, -1.3258], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 27])\noutputes from bert model torch.Size([768, 27])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.2494], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.4240], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.2494, -1.4240], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 30])\noutputes from bert model torch.Size([768, 30])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.2431], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.2427], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.2431, -1.2427], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 22])\noutputes from bert model torch.Size([768, 22])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.0563], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.3762], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.0563, -1.3762], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 38])\noutputes from bert model torch.Size([768, 38])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.1513], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.5463], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.1513, -1.5463], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 28])\noutputes from bert model torch.Size([768, 28])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.1694], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.3294], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.1694, -1.3294], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 13])\noutputes from bert model torch.Size([768, 13])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.0508], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.9371], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.0508, -1.9371], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 12])\noutputes from bert model torch.Size([768, 12])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.2124], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.9589], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.2124, -1.9589], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 33])\noutputes from bert model torch.Size([768, 33])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.3450], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.3726], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.3450, -1.3726], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 19])\noutputes from bert model torch.Size([768, 19])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.0275], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.4262], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.0275, -1.4262], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 13])\noutputes from bert model torch.Size([768, 13])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.3066], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.2101], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.3066, -1.2101], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 33])\noutputes from bert model torch.Size([768, 33])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.3270], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.2729], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.3270, -1.2729], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 6])\noutputes from bert model torch.Size([768, 6])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.3138], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.2617], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.3138, -1.2617], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 21])\noutputes from bert model torch.Size([768, 21])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.2271], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.8000], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.2271, -1.8000], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 38])\noutputes from bert model torch.Size([768, 38])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.0069], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.1995], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.0069, -1.1995], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 37])\noutputes from bert model torch.Size([768, 37])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.1573], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.1970], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.1573, -1.1970], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 14])\noutputes from bert model torch.Size([768, 14])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.1086], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.4701], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.1086, -1.4701], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 15])\noutputes from bert model torch.Size([768, 15])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.0723], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.6218], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.0723, -1.6218], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 27])\noutputes from bert model torch.Size([768, 27])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.1440], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.1176], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.1440, -1.1176], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 33])\noutputes from bert model torch.Size([768, 33])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.3050], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.5553], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.3050, -1.5553], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 21])\noutputes from bert model torch.Size([768, 21])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.1578], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.1553], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.1578, -1.1553], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 12])\noutputes from bert model torch.Size([768, 12])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.0115], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.2559], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.0115, -1.2559], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 12])\noutputes from bert model torch.Size([768, 12])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.0738], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.2766], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.0738, -1.2766], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 13])\noutputes from bert model torch.Size([768, 13])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.2318], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.1331], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.2318, -1.1331], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 28])\noutputes from bert model torch.Size([768, 28])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.0017], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.1673], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.0017, -1.1673], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 17])\noutputes from bert model torch.Size([768, 17])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.0224], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.4378], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-0.0224, -1.4378], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 25])\noutputes from bert model torch.Size([768, 25])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.2519], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.2353], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.2519, -1.2353], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 15])\noutputes from bert model torch.Size([768, 15])\ntorch.Size([11])\nprinting Psk_hate=tensor([-0.0004], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-0.9998], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([-4.4760e-04, -9.9980e-01], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 15])\noutputes from bert model torch.Size([768, 15])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.1805], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.1385], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.1805, -1.1385], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\noutputes from bert model torch.Size([768, 15])\noutputes from bert model torch.Size([768, 15])\ntorch.Size([11])\nprinting Psk_hate=tensor([0.1536], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1]) and Psk_not_hate=tensor([-1.6102], device='cuda:0', grad_fn=<SqueezeBackward4>) shape=torch.Size([1])\nprinting y_preds=tensor([ 0.1536, -1.6102], device='cuda:0', grad_fn=<CatBackward0>) shape=torch.Size([2])\n","output_type":"stream"},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print(hate_space_weights.shape,not_hate_space_weights.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:53:01.066303Z","iopub.status.idle":"2024-03-04T13:53:01.066670Z","shell.execute_reply.started":"2024-03-04T13:53:01.066481Z","shell.execute_reply":"2024-03-04T13:53:01.066495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(hate_space,not_hate_space)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:53:01.067683Z","iopub.status.idle":"2024-03-04T13:53:01.068014Z","shell.execute_reply.started":"2024-03-04T13:53:01.067855Z","shell.execute_reply":"2024-03-04T13:53:01.067869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hate_space_weights","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:53:01.068945Z","iopub.status.idle":"2024-03-04T13:53:01.069245Z","shell.execute_reply.started":"2024-03-04T13:53:01.069096Z","shell.execute_reply":"2024-03-04T13:53:01.069109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.concat((hate_space, not_hate_space)).shape","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:53:01.071255Z","iopub.status.idle":"2024-03-04T13:53:01.071712Z","shell.execute_reply.started":"2024-03-04T13:53:01.071472Z","shell.execute_reply":"2024-03-04T13:53:01.071492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct = 0\ntotal = len(y_test)\n\ntrue = []\npreds = []\n\nwith torch.inference_mode():\n    for i, batch in enumerate(test_loader):\n        if i < 1000 == 0:\n            continue\n        X, y = batch\n        Psk_hate, Psk_not_hate = model0(X)\n\n        y_predict = torch.argmax(torch.tensor([Psk_hate.mean().item(), Psk_not_hate.mean().item()]))\n\n        true.extend(y)\n        preds.append(y_predict)\n\n        cur = torch.eq(y_predict, y)\n\n        correct += torch.sum(cur)\n\nprint(f\"Test Accuracy: {correct/total}\")\nprint(f\"Test Accuracy: {torch.sum(torch.eq(torch.tensor(true), torch.tensor(preds))) / total}\")       ","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:53:01.072967Z","iopub.status.idle":"2024-03-04T13:53:01.073392Z","shell.execute_reply.started":"2024-03-04T13:53:01.073173Z","shell.execute_reply":"2024-03-04T13:53:01.073192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score\n\nprint(precision_score(y_test, preds, average='macro'))\nprint(recall_score(y_test, preds, average='macro'))","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:53:01.074944Z","iopub.status.idle":"2024-03-04T13:53:01.075282Z","shell.execute_reply.started":"2024-03-04T13:53:01.075119Z","shell.execute_reply":"2024-03-04T13:53:01.075134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save(\"/kaggle/working/weights.txt\", [hate_space,not_hate_space,hate_space_weights,not_hate_space_weights])","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:53:01.076480Z","iopub.status.idle":"2024-03-04T13:53:01.076818Z","shell.execute_reply.started":"2024-03-04T13:53:01.076658Z","shell.execute_reply":"2024-03-04T13:53:01.076673Z"},"trusted":true},"execution_count":null,"outputs":[]}]}